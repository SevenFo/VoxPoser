{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-04T03:41:48.090362Z",
     "iopub.status.busy": "2024-02-04T03:41:48.089830Z",
     "iopub.status.idle": "2024-02-04T03:41:48.217212Z",
     "shell.execute_reply": "2024-02-04T03:41:48.216235Z",
     "shell.execute_reply.started": "2024-02-04T03:41:48.090325Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ca10be48dd4dc28b4ea0127b4d5160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_path = \"/models/deepseek-coder-6.7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, torch_dtype=torch.bfloat16).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controlled_object = parse_query_obj('controlled object')\n",
      "current_position = controlled_object.position\n",
      "composer(\"move to 10cm above the table\")\n",
      "composer(f\"move to 10cm above the tree\")\n",
      "composer(f\"move to 10cm above the sofa\")\n",
      "\n",
      "# Execute the commands\n",
      "execute()\n",
      "\n",
      "Time taken: 4.173993825912476 seconds, Length: 260 characters, ratio: 62.29046108930491 characters per second.\n"
     ]
    }
   ],
   "source": [
    "prompt_file_path = \"/mnt/workspace/src/prompts/pyrep_quadcopter/real_planner_prompt.txt\"\n",
    "descriptions = \"\\nobjects = ['table', 'tree', 'sofa']\\n# Query: fly to the table, then fly to the tree, and at last fly to the sofa\"\n",
    "with open(prompt_file_path, \"r\") as f:\n",
    "    prompt = f.read().strip()\n",
    "messages=[\n",
    "    { 'role': 'user', 'content': f\"continue below code, do not generate any non-cdoe message, only allowed python code\\n\\n{prompt}\\n{descriptions}\"}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "# tokenizer.eos_token_id is the id of <|EOT|> token\n",
    "import time\n",
    "start_time = time.time()\n",
    "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
    "end_time = time.time()\n",
    "result = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
    "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))\n",
    "print(f\"Time taken: {end_time - start_time} seconds, Length: {len(result)} characters, ratio: {len(result)/(end_time - start_time)} characters per second.\")\n",
    "del outputs\n",
    "del result\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-06T09:13:51.621740Z",
     "iopub.status.busy": "2024-02-06T09:13:51.621239Z",
     "iopub.status.idle": "2024-02-06T09:14:17.846036Z",
     "shell.execute_reply": "2024-02-06T09:14:17.845047Z",
     "shell.execute_reply.started": "2024-02-06T09:13:51.621695Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"generated_text\":\" and neural network.\\n\\nDeep learning is a subset of machine learning, which is essentially a neural network with three or more layers. These neural networks attempt to simulate the behavior of the human brain—albeit far from matching its ability—in order to \\\"learn\\\" from large amounts of data. While a neural network with a single layer can still make approximate predictions, additional hidden layers can help to optimize accuracy.\\n\\nNeural networks are composed of layers of nodes, or \\\"neurons,\\\" which are interconnected. Each connection, like the synapses in a brain, can transmit a signal from one neuron to another. The signals can be binary (representing 0 or 1) or continuous (representing any value between 0 and 1).\\n\\nThe \\\"learning\\\" in deep learning is achieved through a process called backpropagation, which adjusts the weights of the connections based on the difference between the predicted output and the actual output. This process is repeated many times, each time using a different input, until the network's predictions are as accurate as possible.\\n\\nDeep learning has been used for a variety of tasks, including image recognition, natural language processing, and game playing. It's particularly useful for tasks where it's difficult to program the exact rules that govern the behavior of a system.\\n\\nHere is a simple example of a neural network in Python using the Keras library:\\n\\n```python\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\n\\n# Create a new sequential model\\nmodel = Sequential()\\n\\n# Add a dense layer with 10 neurons\\nmodel.add(Dense(10, input_dim=8, activation='relu'))\\n\\n# Add a dense layer with 8 neurons\\nmodel.add(Dense(8, activation='relu'))\\n\\n# Add a dense layer with 1 neuron\\nmodel.add(Dense(1, activation='sigmoid'))\\n\\n# Compile the model\\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n\\n# Train the model\\nmodel.fit(X_train, y_train, epochs=100, batch_size=10)\\n```\\n\\nIn this example, the model is a neural network with one input layer\"}\n",
      "KeyError: 'result'\n",
      "b'{\"generated_text\":\" and neural network.\\\\n\\\\nDeep learning is a subset of machine learning, which is essentially a neural network with three or more layers. These neural networks attempt to simulate the behavior of the human brain\\xe2\\x80\\x94albeit far from matching its ability\\xe2\\x80\\x94in order to \\\\\"learn\\\\\" from large amounts of data. While a neural network with a single layer can still make approximate predictions, additional hidden layers can help to optimize accuracy.\\\\n\\\\nNeural networks are composed of layers of nodes, or \\\\\"neurons,\\\\\" which are interconnected. Each connection, like the synapses in a brain, can transmit a signal from one neuron to another. The signals can be binary (representing 0 or 1) or continuous (representing any value between 0 and 1).\\\\n\\\\nThe \\\\\"learning\\\\\" in deep learning is achieved through a process called backpropagation, which adjusts the weights of the connections based on the difference between the predicted output and the actual output. This process is repeated many times, each time using a different input, until the network\\'s predictions are as accurate as possible.\\\\n\\\\nDeep learning has been used for a variety of tasks, including image recognition, natural language processing, and game playing. It\\'s particularly useful for tasks where it\\'s difficult to program the exact rules that govern the behavior of a system.\\\\n\\\\nHere is a simple example of a neural network in Python using the Keras library:\\\\n\\\\n```python\\\\nfrom keras.models import Sequential\\\\nfrom keras.layers import Dense\\\\n\\\\n# Create a new sequential model\\\\nmodel = Sequential()\\\\n\\\\n# Add a dense layer with 10 neurons\\\\nmodel.add(Dense(10, input_dim=8, activation=\\'relu\\'))\\\\n\\\\n# Add a dense layer with 8 neurons\\\\nmodel.add(Dense(8, activation=\\'relu\\'))\\\\n\\\\n# Add a dense layer with 1 neuron\\\\nmodel.add(Dense(1, activation=\\'sigmoid\\'))\\\\n\\\\n# Compile the model\\\\nmodel.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\\\n\\\\n# Train the model\\\\nmodel.fit(X_train, y_train, epochs=100, batch_size=10)\\\\n```\\\\n\\\\nIn this example, the model is a neural network with one input layer\"}'\n",
      "{\"inputs\": \"write a python code about what is deep learning\", \"parameters\": {\"max_new_tokens\": 512, \"temperature\": 0.1}}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "messages = []\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hello\"\n",
    "    }\n",
    ")\n",
    "\n",
    "payload = json.dumps(\n",
    "    {\n",
    "        \"inputs\": \"write a python code about what is deep learning\",\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 512,\n",
    "            \"temperature\": 0.1\n",
    "        }\n",
    "    }\n",
    ")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "try:\n",
    "    response = requests.request(\n",
    "        \"POST\",\n",
    "        f'{\"http://192.168.1.252:40906\"}/generate',\n",
    "        headers=headers,\n",
    "        data=payload,\n",
    "    )\n",
    "    print(response.text)\n",
    "\n",
    "    code_str = response.json()[\"result\"]\n",
    "except KeyError as e:\n",
    "    print(\"KeyError:\", e)\n",
    "    print(response.content)\n",
    "    print(payload)\n",
    "    exit(1)\n",
    "    # todo: if reach the max length of API limit, need to switch to a shorter version\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
